{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter is used as main data source for sentiment analytic. Tweets will be streamed to Kafka using Avro as data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'x'\n",
    "consumer_secret = 'x'\n",
    "\n",
    "access_token = 'x'\n",
    "access_token_secret = 'x'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listener class for Twitter's stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import avro.schema\n",
    "import io, random\n",
    "from avro.io import DatumWriter\n",
    "import json\n",
    "\n",
    "class TwitterStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, kafka_producer):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.kafka_producer = kafka_producer\n",
    "        self.topic = 'twitter'\n",
    "        \n",
    "        schema_path =\"twitter.avsc\"\n",
    "        self.schema = avro.schema.Parse(open(schema_path).read())\n",
    "        self.writer = avro.io.DatumWriter(self.schema)\n",
    "        \n",
    "    def _build_tweet(self, status):\n",
    "        tweet = {}\n",
    "        tweet['id'] = status.id_str\n",
    "        tweet['text'] = status.text\n",
    "        tweet['source'] = status.source\n",
    "        tweet['lang'] = status.lang\n",
    "        \n",
    "        return tweet\n",
    "    \n",
    "    def _encode_tweet(self, msg):\n",
    "        bytes_writer = io.BytesIO()\n",
    "        encoder = avro.io.BinaryEncoder(bytes_writer)\n",
    "        self.writer.write(msg, encoder)\n",
    "        tweet = bytes_writer.getvalue()\n",
    "        \n",
    "        return tweet\n",
    "\n",
    "    def _produce_tweet(self, tweet):\n",
    "        producer.produce(self.topic, self._encode_tweet(tweet))\n",
    "        \n",
    "    def on_status(self, status):\n",
    "        tweet = self._build_tweet(status)\n",
    "        self._produce_tweet(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kafka Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "producer = Producer({'bootstrap.servers': 'localhost:9092'})\n",
    "stream_listener = TwitterStreamListener(producer)\n",
    "\n",
    "twitter_stream = tweepy.Stream(auth = api.auth, listener = stream_listener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_pattern = ['putin']\n",
    "twitter_stream.filter(track=search_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
